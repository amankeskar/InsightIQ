# ğŸ¤– InsightIQ

InsightIQ is a locally running, AI-powered internal knowledge assistant that lets you **ask natural language questions from your own PDF documents**. Powered by fast open-source LLMs via [Ollama](https://ollama.com), this tool is designed to break data silos and unlock insights instantly.

---

## ğŸš€ Features

- ğŸ“„ Upload PDFs directly through the UI
- ğŸ§  Text is chunked and embedded with `sentence-transformers`
- âš¡ Fast semantic search using FAISS vector store
- ğŸ¤– Query answers using local LLMs (e.g., Mistral, TinyLlama, LLaMA3, Gemma)
- ğŸ’¬ Clean Streamlit UI with chat history and timestamps
- ğŸ“¥ All data stays on your machine

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- [Streamlit](https://streamlit.io)
- [LangChain](https://www.langchain.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [HuggingFace Transformers](https://huggingface.co/transformers/)
- [Ollama](https://ollama.com/) (for running local LLMs)

---

## ğŸ“¦ Installation

1. **Clone the repo:**
```bash
git clone https://github.com/your-username/insightiq.git
cd insightiq
```

2. **Create and activate virtual environment:**
```bash
python -m venv venv
source venv/bin/activate    # or venv\Scripts\activate on Windows
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Install and run Ollama:**  
[Download Ollama](https://ollama.com/download) and install a model, e.g.:
```bash
ollama run mistral
```

5. **Run the app:**
```bash
streamlit run app.py
```

---

## ğŸ“‚ Folder Structure
```
â”œâ”€â”€ app.py                  # Main Streamlit interface
â”œâ”€â”€ chat_engine.py          # Handles QA interaction with models
â”œâ”€â”€ embed_docs.py           # Document loader & splitter
â”œâ”€â”€ vector_store.py         # Embeddings + FAISS indexing
â”œâ”€â”€ sample_docs/            # Folder for user PDFs
â”œâ”€â”€ faiss_index/            # Generated vector store
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ“¸ Demo

### App Screenshots

#### Landing Page
![Landing Page](Images/Landing_Page.png)
*The main dashboard of InsightIQ, showing the app title and a clean interface for document Q&A.*

#### File Upload
![File Upload](Images/File_Upload.png)
*Upload your PDF documents directly through the sidebar for instant knowledge ingestion.*

#### Model Types
![Model Types](Images/Model_Types.png)
*Select from available local LLMs (Mistral, TinyLlama, Llama3, Gemma) to power your Q&A.*

#### Thinking Spinner
![Thinking](Images/Thinking.png)
*A spinner animation appears while the app processes your question and generates an answer.*

#### Answer Display
![Answer](Images/Answer.png)
*Answers are displayed in a highlighted box, with chat history saved in the sidebar for reference.*

---

## ğŸ‘¨â€ğŸ’» Author
Built by [Aman Keskar](https://linkedin.com/in/aman-keskar) â€” Master's in Information Systems, Syracuse University.

---

## âš–ï¸ License
MIT License

---

## ğŸ™Œ Contribute / Feedback
PRs and feedback are welcome! Feel free to fork the repo or open issues for improvements.
