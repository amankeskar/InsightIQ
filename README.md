# InsightIQ

## What the app does
This app helps you embed, search, and chat with your internal documents using LLMs (Ollama, OpenAI, etc.) and LangChain. It supports PDF ingestion, vector search, and a chat interface for Q&A over your docs.

## How to run it
1. Install Python 3.10+ and Ollama (if using local LLMs).
2. Clone this repo and navigate to the project folder.
3. Create a `.env` file with your API keys (if needed).
4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
5. Run the app:
   ```bash
   streamlit run app.py
   ```

## System requirements
- Python 3.10+
- Ollama (for local LLMs)
- Streamlit
- LangChain
- OpenAI API key (if using OpenAI)

## Optional: Screenshots
_Add screenshots of your app UI here._
